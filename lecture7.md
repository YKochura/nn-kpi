class: middle, center, title-slide
# –ù–µ–π—Ä–æ–Ω–Ω—ñ –º–µ—Ä–µ–∂—ñ

–õ–µ–∫—Ü—ñ—è 7: –ö–æ–º–ø'—é—Ç–µ—Ä–Ω–∏–π –∑—ñ—Ä –Ü–Ü

<br><br>
–ö–æ—á—É—Ä–∞ –Æ—Ä—ñ–π –ü–µ—Ç—Ä–æ–≤–∏—á<br>
[iuriy.kochura@gmail.com](mailto:iuriy.kochura@gmail.com) <br>
<a href="https://t.me/y_kochura">@y_kochura</a> <br>

---

class:  black-slide,
background-image: url(./figures/lec1/nn.jpg)
background-size: cover

<br>
# –°—å–æ–≥–æ–¥–Ω—ñ
.larger-x[<p class="shadow" style="line-height: 250%;">–Ø–∫ —Å—Ç–≤–æ—Ä—é–≤–∞—Ç–∏ –Ω–µ–π—Ä–æ–Ω–Ω—ñ –º–µ—Ä–µ–∂—ñ –¥–ª—è –¥–µ—è–∫–∏—Ö –ø—Ä–æ—Å—É–Ω—É—Ç–∏—Ö –∑–∞–¥–∞—á –∫–æ–º–ø'—é—Ç–µ—Ä–Ω–æ–≥–æ –∑–æ—Ä—É: <br>

üéôÔ∏è –ö–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è <br>
üéôÔ∏è –î–µ—Ç–µ–∫—Ü—ñ—è –æ–±'—î–∫—Ç—ñ–≤ <br>
üéôÔ∏è –°–µ–≥–º–µ–Ω—Ç–∞—Ü—ñ—è <br>
</p>]

---


class: middle

.width-90.center[![](figures/lec7/tasks.jpg)]

.footnote[–î–∂–µ—Ä–µ–ª–æ: [Aur√©lien G√©ron](https://www.oreilly.com/content/introducing-capsule-networks/), 2018.]

???

–î–ª—è –∫–æ–∂–Ω–æ—ó –∑ —Ü–∏—Ö –∑–∞–¥–∞—á –ø–æ—Ç—Ä—ñ–±–Ω–∞ —Å–≤–æ—è –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞ –Ω–µ–π—Ä–æ–Ω–Ω–æ—ó –º–µ—Ä–µ–∂—ñ.

---

class: blue-slide, middle, center
count: false

.larger-xx[–ö–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è]

–ü–æ—Ä–∞–¥–∏ –∑ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è ConvNet –¥–ª—è –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó –∑–æ–±—Ä–∞–∂–µ–Ω—å

---


class: middle

# –ó–≥–æ—Ä—Ç–∫–æ–≤—ñ –Ω–µ–π—Ä–æ–Ω–Ω—ñ –º–µ—Ä–µ–∂—ñ

- –ó–≥–æ—Ä—Ç–∫–æ–≤—ñ –Ω–µ–π—Ä–æ–Ω–Ω—ñ –º–µ—Ä–µ–∂—ñ –ø–æ—î–¥–Ω—É—é—Ç—å –∑–≥–æ—Ä—Ç–∫–æ–≤—ñ —à–∞—Ä–∏, —à–∞—Ä–∏ –∞–≥—Ä–µ–≥–∞—Ü—ñ—ó (pooling) —Ç–∞ –ø–æ–≤–Ω–æ–∑–≤‚Äô—è–∑–Ω—ñ —à–∞—Ä–∏.
- –ó–∞–±–µ–∑–ø–µ—á—É—é—Ç—å –ø–µ—Ä–µ–¥–æ–≤—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –¥–ª—è .bold[–ø—Ä–æ—Å—Ç–æ—Ä–æ–≤–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω–∏—Ö –¥–∞–Ω–∏—Ö], —Ç–∞–∫–∏—Ö —è–∫ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è, –∑–≤—É–∫ –∞–±–æ —Ç–µ–∫—Å—Ç. 

.center.width-110[![](figures/lec5/lenet.svg)]

.footnote[–î–∂–µ—Ä–µ–ª–æ: [Dive Into Deep Learning](https://d2l.ai/), 2020.]

???
–ü—Ä–æ—Å—Ç–æ—Ä–æ–≤–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω—ñ –¥–∞–Ω—ñ ‚Äî —Ü–µ —Ç–∞–∫—ñ –¥–∞–Ω—ñ, –≤ —è–∫–∏—Ö –≤–∞–∂–ª–∏–≤–µ —Ä–æ–∑—Ç–∞—à—É–≤–∞–Ω–Ω—è –µ–ª–µ–º–µ–Ω—Ç—ñ–≤ —É –ø—Ä–æ—Å—Ç–æ—Ä—ñ, —Ç–æ–±—Ç–æ —î —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –∞–±–æ –≤–∑–∞—î–º–æ–∑–≤‚Äô—è–∑–∫–∏ –º—ñ–∂ —Å—É—Å—ñ–¥–Ω—ñ–º–∏ –µ–ª–µ–º–µ–Ω—Ç–∞–º–∏.

–ü—Ä–∏–∫–ª–∞–¥–∏:

*–ó–æ–±—Ä–∞–∂–µ–Ω–Ω—è*

- –ö–æ–∂–µ–Ω –ø—ñ–∫—Å–µ–ª—å –º–∞—î —Å–≤–æ—î –º—ñ—Å—Ü–µ, —ñ –∑–Ω–∞—á–µ–Ω–Ω—è –ø—ñ–∫—Å–µ–ª—ñ–≤ –ø–æ—Ä—É—á —á–∞—Å—Ç–æ –ø–æ–≤‚Äô—è–∑–∞–Ω—ñ.

- –ù–∞–ø—Ä–∏–∫–ª–∞–¥, –∫—Ä–∞—ó –æ–±'—î–∫—Ç—ñ–≤, —Ñ–æ—Ä–º–∏ ‚Äî —Ü–µ –≤—Å–µ –ø—Ä–æ—Å—Ç–æ—Ä–æ–≤—ñ –æ–∑–Ω–∞–∫–∏.

*–¢–µ–∫—Å—Ç*

 - –†–æ–∑—Ç–∞—à—É–≤–∞–Ω–Ω—è —Å–ª—ñ–≤ —É —Ä–µ—á–µ–Ω–Ω—ñ –º–∞—î –∑–Ω–∞—á–µ–Ω–Ω—è.

 - –•–æ—á —Ç–µ–∫—Å—Ç –Ω–µ —î —Ñ—ñ–∑–∏—á–Ω–∏–º –ø—Ä–æ—Å—Ç–æ—Ä–æ–º, –∞–ª–µ –ø–æ—Ä—è–¥–æ–∫ ‚Äî —Ü–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω–∞ –ø–æ—Å–ª—ñ–¥–æ–≤–Ω—ñ—Å—Ç—å.

---

class: middle

# –ö–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è
- –ê–∫—Ç–∏–≤–∞—Ü—ñ—è —É –≤–∏—Ö—ñ–¥–Ω–æ–º—É —à–∞—Ä—ñ &mdash; —Ü–µ .bold[Softmax]-–∞–∫—Ç–∏–≤–∞—Ü—ñ—è, —è–∫–∞ —Ñ–æ—Ä–º—É—î –≤–µ–∫—Ç–æ—Ä –π–º–æ–≤—ñ—Ä–Ω—ñ—Å–Ω–∏—Ö –æ—Ü—ñ–Ω–æ–∫ $$\mathbf{\hat y} = [\hat y\_1, \hat y\_2, \ldots, \hat y\_C ] \in \bigtriangleup^C$$
$$\sum_{i = 1}^C \hat y_i = 1$$
$$\hat y\_i = P(Y=i|\mathbf{x}) = \text{softmax}(z\_i) = \frac{\exp^{z\_i}}{\sum^C\_j \exp^{z\_j}},$$ –¥–µ $C$ &mdash; –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∫–ª–∞—Å—ñ–≤;
- –§—É–Ω–∫—Ü—ñ—è –≤—Ç—Ä–∞—Ç &mdash; –ø–µ—Ä–µ—Ö—Ä–µ—Å–Ω–∞ –µ–Ω—Ç—Ä–æ–ø—ñ—è: $\mathcal{L} = -\sum_{i=1}^{C} y_i \log(\hat{y}_i)$

---

class: middle

# –¢—Ä–∏ —Å–ø–æ—Å–æ–±–∏ –ø–æ–∫—Ä–∞—â–∏—Ç–∏ –¥–∞–Ω—ñ

.bold[–ù–µ—Å—Ç–∞—á–∞ –¥–∞–Ω–∏—Ö] &mdash; –Ω–∞–π–±—ñ–ª—å—à–µ –æ–±–º–µ–∂–µ–Ω–Ω—è –¥–ª—è –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ –º–æ–¥–µ–ª–µ–π –≥–ª–∏–±–æ–∫–æ–≥–æ –Ω–∞–≤—á–∞–Ω–Ω—è.
1. –ó–±—ñ—Ä —Ç–∞ –∞–Ω–æ—Ç–∞—Ü—ñ—è –¥–æ–¥–∞—Ç–∫–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö –∑–∞–∑–≤–∏—á–∞–π —î –¥–æ—Ä–æ–≥–∏–º —ñ —Ç—Ä—É–¥–æ–º—ñ—Å—Ç–∫–∏–º –∑–∞–≤–¥–∞–Ω–Ω—è–º.

.center.width-50[![](figures/lec7/google-street-view-car.jpg)]

---

class: middle
count: false

# –¢—Ä–∏ —Å–ø–æ—Å–æ–±–∏ –ø–æ–∫—Ä–∞—â–∏—Ç–∏ –¥–∞–Ω—ñ

.bold[–ù–µ—Å—Ç–∞—á–∞ –¥–∞–Ω–∏—Ö] &mdash; –Ω–∞–π–±—ñ–ª—å—à–µ –æ–±–º–µ–∂–µ–Ω–Ω—è –¥–ª—è –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ –º–æ–¥–µ–ª–µ–π –≥–ª–∏–±–æ–∫–æ–≥–æ –Ω–∞–≤—á–∞–Ω–Ω—è.
1. .inactive[–ó–±—ñ—Ä –¥–æ–¥–∞—Ç–∫–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö –∑–∞–∑–≤–∏—á–∞–π —î –¥–æ—Ä–æ–≥–∏–º —ñ —Ç—Ä—É–¥–æ–º—ñ—Å—Ç–∫–∏–º –∑–∞–≤–¥–∞–Ω–Ω—è–º.]
1. –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Å–∏–Ω—Ç–µ—Ç–∏—á–Ω–∏—Ö –¥–∞–Ω–∏—Ö –º–æ–∂–µ –±—É—Ç–∏ —Å–∫–ª–∞–¥–Ω–∏–º –∑–∞–≤–¥–∞–Ω–Ω—è —ñ –Ω–µ –≤—ñ–¥–æ–±—Ä–∞–∂–∞—Ç–∏ —Ä–µ–∞–ª—å–Ω–∏–π —Ä–æ–∑–ø–æ–¥—ñ–ª.

.center.width-90[![](figures/lec7/marilyn_ethnicity_hu186fc8fda88363407e2c23753c57080f_560556_1200x1200_fit_lanczos_3.png)]
–ú–µ—Ä–∏–ª—ñ–Ω –ú–æ–Ω—Ä–æ –≤ –∞–∑—ñ–π—Å—å–∫–æ–º—É, –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–æ–º—É —Ç–∞ –∞—Ñ—Ä–∏–∫–∞–Ω—Å—å–∫–æ–º—É —Å—Ç–∏–ª—è—Ö

.footnote[–î–∂–µ—Ä–µ–ª–æ: [Generative models and bias](https://blog.demaupeou.com/post/generative-models-bias/), 2021.]

---

class: middle
count: false

# –¢—Ä–∏ —Å–ø–æ—Å–æ–±–∏ –ø–æ–∫—Ä–∞—â–∏—Ç–∏ –¥–∞–Ω—ñ

.bold[–ù–µ—Å—Ç–∞—á–∞ –¥–∞–Ω–∏—Ö] &mdash; –Ω–∞–π–±—ñ–ª—å—à–µ –æ–±–º–µ–∂–µ–Ω–Ω—è –¥–ª—è –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ –º–æ–¥–µ–ª–µ–π –≥–ª–∏–±–æ–∫–æ–≥–æ –Ω–∞–≤—á–∞–Ω–Ω—è.
1. .inactive[–ó–±—ñ—Ä –¥–æ–¥–∞—Ç–∫–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö –∑–∞–∑–≤–∏—á–∞–π —î –¥–æ—Ä–æ–≥–∏–º —ñ —Ç—Ä—É–¥–æ–º—ñ—Å—Ç–∫–∏–º –∑–∞–≤–¥–∞–Ω–Ω—è–º.]
1. .inactive[–°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Å–∏–Ω—Ç–µ—Ç–∏—á–Ω–∏—Ö –¥–∞–Ω–∏—Ö –º–æ–∂–µ –±—É—Ç–∏ —Å–∫–ª–∞–¥–Ω–∏–º –∑–∞–≤–¥–∞–Ω–Ω—è —ñ –Ω–µ –≤—ñ–¥–æ–±—Ä–∞–∂–∞—Ç–∏ —Ä–µ–∞–ª—å–Ω–∏–π —Ä–æ–∑–ø–æ–¥—ñ–ª.]
1. .bold[–î–æ–ø–æ–≤–Ω–µ–Ω–Ω—è] –¥–∞–Ω–∏—Ö –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é –±–∞–∑–æ–≤–∏—Ö –ø–µ—Ä–µ—Ç–≤–æ—Ä–µ–Ω—å &mdash; –ø—Ä–æ—Å—Ç–∏–π —Ç–∞ –µ—Ñ–µ–∫—Ç–∏–≤–Ω–∏–π –ø—ñ–¥—Ö—ñ–¥, –∞–ª–µ –ø–æ—à—É–∫ —Ö–æ—Ä–æ—à–æ—ó —Å—Ç—Ä–∞—Ç–µ–≥—ñ—ó –¥–ª—è –¥–æ–ø–æ–≤–Ω–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö –º–æ–∂–µ –≤–∏–º–∞–≥–∞—Ç–∏ —á–∏—Å–ª–µ–Ω–Ω–∏—Ö –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ñ–≤. 

.center.width-40[![](figures/lec7/augment.png)]

.footnote[–î–∂–µ—Ä–µ–ª–æ: [DeepAugment](https://github.com/barisozmen/deepaugment), 2020.]

---


class: middle
background-size: contain

background-image: url(./figures/lec7/augmentation-ua.png)

.footnote[–î–∂–µ—Ä–µ–ª–æ: [DeepAugment](https://github.com/barisozmen/deepaugment), 2020.]

---

class: middle

.center.width-100[![](figures/lec7/deepaugment-ua.png)]

$$\text{Error Reduction} = \frac{E\_\text{old} - E\_\text{new}}{E\_\text{old}}\cdot 100\% = \frac{0.143 - 0.058}{0.143}\cdot 100\% = 59.4\% $$

.footnote[–î–∂–µ—Ä–µ–ª–æ: [DeepAugment](https://github.com/barisozmen/deepaugment), 2020.]

---


class: middle

# –ü–æ–ø–µ—Ä–µ–¥–Ω—å–æ –Ω–∞–≤—á–µ–Ω—ñ –º–æ–¥–µ–ª—ñ

- –ù–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ ¬´–∑ –Ω—É–ª—è¬ª –º–æ–∂–µ —Ç—Ä–∏–≤–∞—Ç–∏ .bold[–¥–Ω—ñ] –∞–±–æ –Ω–∞–≤—ñ—Ç—å .bold[—Ç–∏–∂–Ω—ñ].
- –ë–∞–≥–∞—Ç–æ –º–æ–¥–µ–ª–µ–π, .bold[–Ω–∞–≤—á–µ–Ω–∏—Ö –Ω–∞ –≤–µ–ª–∏–∫–∏—Ö –Ω–∞–±–æ—Ä–∞—Ö –¥–∞–Ω–∏—Ö], –¥–æ—Å—Ç—É–ø–Ω—ñ —É –≤—ñ–¥–∫—Ä–∏—Ç–æ–º—É –¥–æ—Å—Ç—É–ø—ñ. –á—Ö –º–æ–∂–Ω–∞ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ —è–∫: **–µ–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–∏ –æ–∑–Ω–∞–∫** –∞–±–æ —è–∫ –æ—Å–Ω–æ–≤—É –¥–ª—è —Ä–æ–∑—É–º–Ω–æ—ó *—ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—ó* –ø—Ä–∏ –¥–æ–Ω–∞–≤—á–∞–Ω–Ω—ñ.
- –¢–∞–∫—ñ –º–æ–¥–µ–ª—ñ —Å–ª—ñ–¥ —Ä–æ–∑–≥–ª—è–¥–∞—Ç–∏ —è–∫ .bold[—É–Ω—ñ–≤–µ—Ä—Å–∞–ª—å–Ω—ñ], .bold[–±–∞–≥–∞—Ç–æ—Ä–∞–∑–æ–≤—ñ] –∞–∫—Ç–∏–≤–∏.

???

–°–ª—ñ–¥ –ø—ñ–¥–∫—Ä–µ—Å–ª–∏—Ç–∏, —â–æ —Ü–µ –≤–∂–µ —Å—Ç–∞–ª–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ—é –ø—Ä–∞–∫—Ç–∏–∫–æ—é –≤ –≥–ª–∏–±–æ–∫–æ–º—É –Ω–∞–≤—á–∞–Ω–Ω—ñ. –õ–∏—à–µ –Ω–µ–∑–Ω–∞—á–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Ñ–∞—Ö—ñ–≤—Ü—ñ–≤ —É—Å–µ —â–µ –Ω–∞–≤—á–∞—î –º–æ–¥–µ–ª—ñ –∑ –Ω—É–ª—è.
–ó –ø–æ—à–∏—Ä–µ–Ω–Ω—è–º foundation models —Ç–∞–∫–∏—Ö –≤–∏–ø–∞–¥–∫—ñ–≤ —Å—Ç–∞—î —â–µ –º–µ–Ω—à–µ.

---

class: middle

# –ü–µ—Ä–µ–¥–∞–≤–∞–ª—å–Ω–µ –Ω–∞–≤—á–∞–Ω–Ω—è

- –ë–µ—Ä–µ–º–æ –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ –Ω–∞–≤—á–µ–Ω—É –º–µ—Ä–µ–∂—É, –≤–∏–¥–∞–ª—è—î–º–æ –æ—Å—Ç–∞–Ω–Ω—ñ–π (–∞–±–æ –∫—ñ–ª—å–∫–∞ –æ—Å—Ç–∞–Ω–Ω—ñ—Ö) —à–∞—Ä—ñ–≤ —ñ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ —Ä–µ—à—Ç—É —è–∫ .bold[—Ñ—ñ–∫—Å–æ–≤–∞–Ω–∏–π] –µ–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä –æ–∑–Ω–∞–∫.
- –ù–∞ –æ—Å–Ω–æ–≤—ñ —Ü–∏—Ö –æ–∑–Ω–∞–∫ –Ω–∞–≤—á–∞—î–º–æ .bold[–Ω–æ–≤—É –º–æ–¥–µ–ª—å] –¥–ª—è .bold[–Ω–æ–≤–æ—ó –∑–∞–¥–∞—á—ñ].
- –ß–∞—Å—Ç–æ –ø–æ–∫–∞–∑—É—î –∫—Ä–∞—â—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏, –Ω—ñ–∂ —Ä—É—á–Ω–µ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –æ–∑–Ω–∞–∫ –∞–±–æ –Ω–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ –ª–∏—à–µ –Ω–∞ –Ω–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö.

<br>
.center.width-100[![](figures/lec7/feature-extractor.png)]

.footnote[–î–∂–µ—Ä–µ–ª–æ: Mormont et al, [Comparison of deep transfer learning strategies for digital pathology](http://hdl.handle.net/2268/222511), 2018.]

---

class: middle

.center.width-65[![](figures/lec7/finetune.svg)]

## –¢–æ–Ω–∫–µ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è

–ú–∏ –Ω–µ –ª–∏—à–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ –Ω–∞–≤—á–µ–Ω—É –º–æ–¥–µ–ª—å –¥–ª—è –Ω–æ–≤–æ—ó –∑–∞–¥–∞—á—ñ, –∞–ª–µ –π –¥–æ–∑–≤–æ–ª—è—î–º–æ –º–æ–¥–µ–ª—ñ –∞–¥–∞–ø—Ç—É–≤–∞—Ç–∏—Å—è –¥–æ –Ω–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö, –∑–º—ñ–Ω—é—é—á–∏ —ó—ó –≤–∞–≥–∏ –ø—ñ–¥ —á–∞—Å –Ω–∞–≤—á–∞–Ω–Ω—è.

.footnote[–î–∂–µ—Ä–µ–ª–æ: [Dive Into Deep Learning](https://d2l.ai/), 2020.]

???
–¢–æ–Ω–∫–µ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è ‚Äî —Ü–µ –ø–æ–ø—É–ª—è—Ä–Ω–∏–π –ø—ñ–¥—Ö—ñ–¥ —É –≥–ª–∏–±–æ–∫–æ–º—É –Ω–∞–≤—á–∞–Ω–Ω—ñ, –æ—Å–æ–±–ª–∏–≤–æ –∫–æ–ª–∏ –º–∏ –º–∞—î–º–æ –æ–±–º–µ–∂–µ–Ω—É –∫—ñ–ª—å–∫—ñ—Å—Ç—å –¥–∞–Ω–∏—Ö –¥–ª—è –Ω–æ–≤–æ—ó –∑–∞–¥–∞—á—ñ, –∞–ª–µ –º–æ–∂–µ–º–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ –∑–Ω–∞–Ω–Ω—è, –æ—Ç—Ä–∏–º–∞–Ω—ñ –Ω–∞ —ñ–Ω—à–∏—Ö –≤–µ–ª–∏–∫–∏—Ö –Ω–∞–±–æ—Ä–∞—Ö –¥–∞–Ω–∏—Ö.

---

class: middle

–ú–æ–¥–µ–ª—ñ, —è–∫—ñ –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ –Ω–∞–≤—á–µ–Ω—ñ –Ω–∞ **ImageNet**: –ø–µ—Ä–µ–¥–∞–Ω—ñ/—Ç–æ–Ω–∫–æ –Ω–∞–ª–∞—à—Ç–æ–≤–∞–Ω—ñ –º–µ—Ä–µ–∂—ñ –∑–∞–∑–≤–∏—á–∞–π –ø—Ä–∞—Ü—é—é—Ç—å –∫—Ä–∞—â–µ –Ω–∞–≤—ñ—Ç—å —Ç–æ–¥—ñ, –∫–æ–ª–∏ –≤—Ö—ñ–¥–Ω—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –Ω–∞–ª–µ–∂–∞—Ç—å –¥–æ —ñ–Ω—à–æ—ó –¥–æ–º–µ–Ω–Ω–æ—ó –æ–±–ª–∞—Å—Ç—ñ (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, –±—ñ–æ–º–µ–¥–∏—á–Ω—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è, —Å—É–ø—É—Ç–Ω–∏–∫–æ–≤—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∞–±–æ –∫–∞—Ä—Ç–∏–Ω–∏).

.center.width-75[![](figures/lec7/fine-tuning-results.png)]

.footnote[–î–∂–µ—Ä–µ–ª–æ: Matthia Sabatelli et al, [Deep Transfer Learning for Art Classification Problems](http://openaccess.thecvf.com/content_ECCVW_2018/papers/11130/Sabatelli_Deep_Transfer_Learning_for_Art_Classification_Problems_ECCVW_2018_paper.pdf), 2018.]

---

class: blue-slide, middle, center
count: false

.larger-xx[–î–µ—Ç–µ–∫—Ü—ñ—è –æ–±'—î–∫—Ç—ñ–≤]


---

class: middle

–ù–∞–π–ø—Ä–æ—Å—Ç—ñ—à–∞ —Å—Ç—Ä–∞—Ç–µ–≥—ñ—è –¥–ª—è –ø–µ—Ä–µ—Ö–æ–¥—É –≤—ñ–¥ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó –∑–æ–±—Ä–∞–∂–µ–Ω—å –¥–æ –¥–µ—Ç–µ–∫—Ü—ñ—ó –æ–±'—î–∫—Ç—ñ–≤ &mdash; —Ü–µ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è –ª–æ–∫–∞–ª—å–Ω–∏—Ö –¥—ñ–ª—è–Ω–æ–∫ –Ω–∞ —Ä—ñ–∑–Ω–∏—Ö –º–∞—Å—à—Ç–∞–±–∞—Ö —ñ –≤ —Ä—ñ–∑–Ω–∏—Ö –º—ñ—Å—Ü—è—Ö.

.center.width-80[![](figures/lec7/sliding.gif)]

.footnote[–î–∂–µ—Ä–µ–ª–æ: Francois Fleuret, [EE559 Deep Learning](https://fleuret.org/ee559/), EPFL.]

---

exclude: true
class: middle

## Intersection over Union (IoU)

–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∏–º –ø–æ–∫–∞–∑–Ω–∏–∫–æ–º –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ –¥–ª—è –≤–∏—è–≤–ª–µ–Ω–Ω—è –æ–±'—î–∫—Ç—ñ–≤ —î (Intersection over Union, IoU) –º—ñ–∂ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–æ—é –ø—Ä—è–º–æ–∫—É—Ç–Ω–æ—é —Ä–∞–º–∫–æ—é $\hat{B}$ —Ç–∞ –∞–Ω–æ—Ç–æ–≤–∞–Ω–æ—é –ø—Ä—è–º–æ–∫—É—Ç–Ω–æ—é —Ä–∞–º–∫–æ—é $B$.
$$\text{IoU}(B,\hat{B}) = \frac{\text{area}(B \cap \hat{B})}{\text{area}(B \cup \hat{B})}.$$

.center.width-45[![](figures/lec7/iou.png)]

.footnote[–î–∂–µ—Ä–µ–ª–æ: Francois Fleuret, [EE559 Deep Learning](https://fleuret.org/ee559/), EPFL.]

---


class: middle 

–ü—ñ–¥—Ö—ñ–¥ –∑—ñ —Å–ª–∞–π–¥—ñ–Ω–≥–æ–º –≤—ñ–∫–Ω–∞ –æ—Ü—ñ–Ω—é—î –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ç–æ—Ä –Ω–∞ –≤–µ–ª–∏–∫—ñ–π –∫—ñ–ª—å–∫–æ—Å—Ç—ñ –ø–æ–∑–∏—Ü—ñ–π —Ç–∞ –º–∞—Å—à—Ç–∞–±—ñ–≤.

–¶–µ–π –ø—ñ–¥—Ö—ñ–¥ –∑–∞–∑–≤–∏—á–∞–π —î .bold[–æ–±—á–∏—Å–ª—é–≤–∞–ª—å–Ω–æ –≤–∏—Ç—Ä–∞—Ç–Ω–∏–º], –æ—Å–∫—ñ–ª—å–∫–∏ –µ—Ñ–µ–∫—Ç–∏–≤–Ω—ñ—Å—Ç—å –±–µ–∑–ø–æ—Å–µ—Ä–µ–¥–Ω—å–æ –∑–∞–ª–µ–∂–∏—Ç—å –≤—ñ–¥ —Ä–æ–∑–¥—ñ–ª—å–Ω–æ—ó –∑–¥–∞—Ç–Ω–æ—Å—Ç—ñ —Ç–∞ –∫—ñ–ª—å–∫–æ—Å—Ç—ñ –≤—ñ–∫–æ–Ω, –ø–æ–¥–∞–Ω–∏—Ö –¥–æ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ç–æ—Ä–∞ (—á–∏–º –±—ñ–ª—å—à–µ –≤—ñ–∫–æ–Ω, —Ç–∏–º –∫—Ä–∞—â–µ, –∞–ª–µ –π —Ç–∏–º –¥–æ—Ä–æ–∂—á–µ).

---

# OverFeat 

.grid[
.kol-2-3[

–°–∫–ª–∞–¥–Ω—ñ—Å—Ç—å –ø—ñ–¥—Ö–æ–¥—É –∑—ñ —Å–ª–∞–π–¥—ñ–Ω–≥–æ–º –≤—ñ–∫–Ω–∞ –±—É–ª–∞ –∑–Ω–∏–∂–µ–Ω–∞ –≤ –ø—ñ–æ–Ω–µ—Ä—Å—å–∫—ñ–π –º–µ—Ä–µ–∂—ñ OverFeat (Sermanet et al, 2013) —à–ª—è—Ö–æ–º –¥–æ–¥–∞–≤–∞–Ω–Ω—è –±–ª–æ–∫—É —Ä–µ–≥—Ä–µ—Å—ñ—ó –¥–ª—è –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è –æ–±–º–µ–∂—É–≤–∞–ª—å–Ω–æ—ó —Ä–∞–º–∫–∏ –æ–±'—î–∫—Ç–∞ $(x, y, w, h)$.

]
.kol-1-3[.center.width-100[![](figures/lec7/overfeat.png)]]
]

.footnote[–î–∂–µ—Ä–µ–ª–æ: Francois Fleuret, [EE559 Deep Learning](https://fleuret.org/ee559/), EPFL.]

???
–£ —Ü—ñ–π —Ä–æ–±–æ—Ç—ñ –∞–≤—Ç–æ—Ä–∏ –∑–∞–ø—Ä–æ–ø–æ–Ω—É–≤–∞–ª–∏ –º–µ—Ç–æ–¥ OverFeat, —è–∫–∏–π –ø–æ—î–¥–Ω—É—î –≤ —Å–æ–±—ñ –∑–∞–¥–∞—á—ñ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è, –ª–æ–∫–∞–ª—ñ–∑–∞—Ü—ñ—ó —Ç–∞ –≤–∏—è–≤–ª–µ–Ω–Ω—è –æ–±'—î–∫—Ç—ñ–≤ –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é –∫–æ–Ω–≤–æ–ª—é—Ü—ñ–π–Ω–∏—Ö –Ω–µ–π—Ä–æ–Ω–Ω–∏—Ö –º–µ—Ä–µ–∂ (CNN). –ö–ª—é—á–æ–≤–æ—é —ñ–¥–µ—î—é –±—É–ª–æ –¥–æ–¥–∞–≤–∞–Ω–Ω—è  –±–ª–æ–∫—É —Ä–µ–≥—Ä–µ—Å—ñ—ó –¥–æ –º–µ—Ä–µ–∂—ñ –¥–ª—è –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –ø—Ä—è–º–æ–∫—É—Ç–Ω–æ—ó —Ä–∞–º–∫–∏ –æ–±'—î–∫—Ç–∞ (–∑–∞–º—ñ—Å—Ç—å —Ç—Ä–∞–¥–∏—Ü—ñ–π–Ω–æ–≥–æ –º–µ—Ç–æ–¥—É —Å–ª–∞–π–¥—ñ–Ω–≥–∞ –≤—ñ–∫–Ω–∞), —â–æ –∑–Ω–∞—á–Ω–æ –ø–æ–∫—Ä–∞—â–∏–ª–æ –µ—Ñ–µ–∫—Ç–∏–≤–Ω—ñ—Å—Ç—å —Ç–∞ —à–≤–∏–¥–∫—ñ—Å—Ç—å –≤–∏—è–≤–ª–µ–Ω–Ω—è –æ–±'—î–∫—Ç—ñ–≤ –Ω–∞ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è—Ö.

–¶–µ –±—É–ª–∞ –æ–¥–Ω–∞ –∑ –ø–µ—Ä—à–∏—Ö —Ä–æ–±—ñ—Ç, —è–∫–∞ –¥–µ–º–æ–Ω—Å—Ç—Ä—É–≤–∞–ª–∞ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è CNN –¥–ª—è –ª–æ–∫–∞–ª—ñ–∑–∞—Ü—ñ—ó —Ç–∞ –¥–µ—Ç–µ–∫—Ü—ñ—ó –æ–±'—î–∫—Ç—ñ–≤ –≤ —Ä–µ–∞–ª—å–Ω–∏—Ö —É–º–æ–≤–∞—Ö.

---

class: middle

.center[.width-60[![](figures/lec7/overfeat-grid.png)] 
.width-60[![](figures/lec7/overfeat-predictions.png)]]

–î–ª—è –∫–æ–∂–Ω–æ—ó –ø–æ–∑–∏—Ü—ñ—ó —Ç–∞ –º–∞—Å—à—Ç–∞–±—É:
- –±–ª–æ–∫ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ç–æ—Ä–∞ –≤–∏–≤–æ–¥–∏—Ç—å –∫–ª–∞—Å —Ç–∞ –π–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å (–≤–µ—Ä—Ö–Ω—ñ–π —Ä–∏—Å.);
- –±–ª–æ–∫ —Ä–µ–≥—Ä–µ—Å—ñ—ó –ø–µ—Ä–µ–¥–±–∞—á–∞—î –º—ñ—Å—Ü–µ–∑–Ω–∞—Ö–æ–¥–∂–µ–Ω–Ω—è –æ–±'—î–∫—Ç–∞ (–Ω–∏–∂–Ω—ñ–π —Ä–∏—Å.).

.footnote[–î–∂–µ—Ä–µ–ª–æ: Sermanet et al, 2013.]

---

class: middle

.center.width-60[![](figures/lec7/overfeat-merge.png)]

–¶—ñ –ø—Ä—è–º–æ–∫—É—Ç–Ω—ñ —Ä–∞–º–∫–∏ –≤ –∫—ñ–Ω—Ü–µ–≤–æ–º—É –ø—ñ–¥—Å—É–º–∫—É –æ–±'—î–¥–Ω—É—é—Ç—å—Å—è –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é .bold[Non-Maximum Suppression], —â–æ–± –æ—Ç—Ä–∏–º–∞—Ç–∏ –æ—Å—Ç–∞—Ç–æ—á–Ω—ñ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è –¥–ª—è –º–µ–Ω—à–æ—ó –∫—ñ–ª—å–∫–æ—Å—Ç—ñ –æ–±'—î–∫—Ç—ñ–≤.

.footnote[–î–∂–µ—Ä–µ–ª–æ: Sermanet et al, 2013.]

???

Non-Maximum Suppression (NMS) ‚Äî —Ü–µ –º–µ—Ç–æ–¥, —è–∫–∏–π –¥–æ–ø–æ–º–∞–≥–∞—î —É—Å—É–Ω—É—Ç–∏ –∑–∞–π–≤—ñ —Ç–∞ –¥—É–±–ª—é—é—á—ñ –ø—Ä—è–º–æ–∫—É—Ç–Ω—ñ —Ä–∞–º–∫–∏, –∑–∞–ª–∏—à–∞—é—á–∏ –ª–∏—à–µ –Ω–∞–π–∫—Ä–∞—â—ñ (–∑ –Ω–∞–π–±—ñ–ª—å—à–∏–º–∏ –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç—è–º–∏) –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ –≤–∏—è–≤–ª–µ–Ω–æ–≥–æ –æ–±'—î–∫—Ç–∞.

NMS:
1. –ü–æ—á–∞—Ç–∏ –∑ —É—Å—ñ—Ö –ø—Ä—è–º–æ–∫—É—Ç–Ω–∏—Ö —Ä–∞–º–æ–∫ –≤–∏—è–≤–ª–µ–Ω–Ω—è, –∫–æ–∂–Ω–∞ –∑ —è–∫–∏—Ö –º–∞—î –±–∞–ª –≤–ø–µ–≤–Ω–µ–Ω–æ—Å—Ç—ñ.
2. –í—ñ–¥—Å–æ—Ä—Ç—É–≤–∞—Ç–∏ –≤—Å—ñ —Ä–∞–º–∫–∏ –∑–∞ –±–∞–ª–æ–º –≤–ø–µ–≤–Ω–µ–Ω–æ—Å—Ç—ñ (–≤—ñ–¥ –Ω–∞–π–≤–∏—â–æ–≥–æ –¥–æ –Ω–∞–π–Ω–∏–∂—á–æ–≥–æ).
3. –í–∏–±—Ä–∞—Ç–∏ —Ä–∞–º–∫—É –∑ –Ω–∞–π–≤–∏—â–∏–º –±–∞–ª–æ–º –≤–ø–µ–≤–Ω–µ–Ω–æ—Å—Ç—ñ —Ç–∞ –¥–æ–¥–∞—Ç–∏ —ó—ó –¥–æ —Ñ—ñ–Ω–∞–ª—å–Ω–æ–≥–æ —Å–ø–∏—Å–∫—É –≤–∏—è–≤–ª–µ–Ω–∏—Ö –æ–±'—î–∫—Ç—ñ–≤.
4. –û–±—á–∏—Å–ª–∏—Ç–∏ IoU –º—ñ–∂ —Ü—ñ—î—é —Ä–∞–º–∫–æ—é —Ç–∞ –≤—Å—ñ–º–∞ —ñ–Ω—à–∏–º–∏ –∑–∞–ª–∏—à–∫–æ–≤–∏–º–∏ —Ä–∞–º–∫–∞–º–∏.
5. –í–∏–¥–∞–ª–∏—Ç–∏ —Ä–∞–º–∫–∏ –∑ IoU –º–µ–Ω—à–µ –∑–∞ –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ –≤–∏–∑–Ω–∞—á–µ–Ω–∏–π –ø–æ—Ä—ñ–≥ (–∑–∞–∑–≤–∏—á–∞–π 0.5-0.7).
6. –ü–æ–≤—Ç–æ—Ä—é–≤–∞—Ç–∏ –∫—Ä–æ–∫–∏ 3-5, –ø–æ–∫–∏ –Ω–µ –∑–∞–ª–∏—à–∏—Ç—å—Å—è –æ–¥–Ω–∞ —Ä–∞–º–∫–∞.

IoU = Area of Intersection / Area of Union
(range from 0 (no overlap) to 1 (perfect overlap))

---

class: middle

–ê—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞ OverFeat –º–∞—î –∫—ñ–ª—å–∫–∞ .bold[–Ω–µ–¥–æ–ª—ñ–∫—ñ–≤]:
- —Ü–µ —Ä–æ–∑'—î–¥–Ω–∞–Ω–∞ —Å–∏—Å—Ç–µ–º–∞ (2 –æ–∫—Ä–µ–º—ñ –±–ª–æ–∫–∏ –∑ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–∏–º–∏ –≤—Ç—Ä–∞—Ç–∞–º–∏, —Å–ø–µ—Ü—ñ–∞–ª—å–Ω–∏–π –ø—Ä–æ—Ü–µ—Å –æ–±'—î–¥–Ω–∞–Ω–Ω—è);
- –æ—Ä—ñ—î–Ω—Ç–æ–≤–∞–Ω–∞ –Ω–∞ —Ç–æ—á–Ω–µ –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è –º—ñ—Å—Ü—è (–ª–æ–∫–∞–ª—ñ–∑–∞—Ü—ñ—ó) –æ–±'—î–∫—Ç–∞ –Ω–∞ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—ñ, –∞ –Ω–µ –Ω–∞ –≤–∏—è–≤–ª–µ–Ω–Ω—ñ —Å–∞–º–æ–≥–æ –æ–±'—î–∫—Ç–∞;
- –Ω–µ –≤—Ä–∞—Ö–æ–≤—É—î –∑–∞–≥–∞–ª—å–Ω–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –ø—Ä–∏ –ø—Ä–∏–π–Ω—è—Ç—Ç—ñ —Ä—ñ—à–µ–Ω—å, —á–µ—Ä–µ–∑ —Ü–µ –ø–æ—Ç—Ä—ñ–±–Ω–æ –≤–∏–∫–æ–Ω—É–≤–∞—Ç–∏ –∑–Ω–∞—á–Ω–µ –ø–æ—Å—Ç–æ–±—Ä–æ–±–ª–µ–Ω–Ω—è –¥–ª—è —Ç–æ–≥–æ, —â–æ–± –∑—Ä–æ–±–∏—Ç–∏ –¥–µ—Ç–µ–∫—Ü—ñ—é –æ–±'—î–∫—Ç—ñ–≤ –±—ñ–ª—å—à —É–∑–≥–æ–¥–∂–µ–Ω–æ—é —Ç–∞ —Ç–æ—á–Ω–æ—é.

???

–ê—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞ OverFeat —Å–ø–æ—á–∞—Ç–∫—É —Ñ–æ–∫—É—Å—É—î—Ç—å—Å—è –Ω–∞ –ª–æ–∫–∞–ª—ñ–∑–∞—Ü—ñ—ó –æ–±'—î–∫—Ç–∞: –≤–æ–Ω–∞ –≤–∏–∑–Ω–∞—á–∞—î –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∏ –ø—Ä—è–º–æ–∫—É—Ç–Ω–æ—ó —Ä–∞–º–∫–∏, –¥–µ, –π–º–æ–≤—ñ—Ä–Ω–æ, –∑–Ω–∞—Ö–æ–¥–∏—Ç—å—Å—è –æ–±'—î–∫—Ç. –û–¥–Ω–∞–∫ –≤–æ–Ω–∞ –Ω–µ –æ–ø—Ç–∏–º—ñ–∑—É—î—Ç—å—Å—è –Ω–∞ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–º—É –≤–∏—è–≤–ª–µ–Ω–Ω—ñ –æ–±'—î–∫—Ç–∞ (–≤–∫–ª—é—á–∞—é—á–∏ –ø—Ä–∞–≤–∏–ª—å–Ω—É –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—é —Ç–∞ —Ç–æ—á–Ω–µ –æ–±'—î–¥–Ω–∞–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤). –¶–µ –æ–∑–Ω–∞—á–∞—î, —â–æ –≤ OverFeat –±—ñ–ª—å—à–µ —É–≤–∞–≥–∏ –ø—Ä–∏–¥—ñ–ª—è—î—Ç—å—Å—è –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—é —Ç–æ—á–Ω–æ–≥–æ –º—ñ—Å—Ü—è —Ä–æ–∑—Ç–∞—à—É–≤–∞–Ω–Ω—è –æ–±'—î–∫—Ç–∞, –Ω—ñ–∂ –±–µ–∑–ø–æ—Å–µ—Ä–µ–¥–Ω—å–æ –π–æ–≥–æ –≤–∏—è–≤–ª–µ–Ω–Ω—é —Ç–∞ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó.


---

# YOLO (You Only Look Once)

.center.width-65[![](figures/lec7/yolo-model.png)]

YOLO (Redmon et al., 2015) —Ä–æ–∑–≥–ª—è–¥–∞—î –∑–∞–¥–∞—á—É –¥–µ—Ç–µ–∫—Ü—ñ—ó –æ–±'—î–∫—Ç—ñ–≤ —è–∫ –∑–∞–¥–∞—á—É —Ä–µ–≥—Ä–µ—Å—ñ—ó.

–ó–æ–±—Ä–∞–∂–µ–Ω–Ω—è —Ä–æ–∑–±–∏–≤–∞—î—Ç—å—Å—è –Ω–∞ —Å—ñ—Ç–∫—É —Ä–æ–∑–º—ñ—Ä—É $S \times S$. –î–ª—è –∫–æ–∂–Ω–æ—ó –∫–ª—ñ—Ç–∏–Ω–∫–∏ —Å—ñ—Ç–∫–∏ –ø–µ—Ä–µ–¥–±–∞—á–∞—é—Ç—å—Å—è —Ç–∞–∫—ñ –∑–Ω–∞—á–µ–Ω–Ω—è: $B$ –æ–±–º–µ–∂—É–≤–∞–ª—å–Ω—ñ —Ä–∞–º–∫–∏, –π–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å –¥–ª—è –∫–æ–∂–Ω–æ—ó –∑ —Ü–∏—Ö —Ä–∞–º–æ–∫ —Ç–∞ $C$ –∫–ª–∞—Å–æ–≤–∞ –π–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å. –¶—ñ –ø—Ä–æ–≥–Ω–æ–∑–∏ –∫–æ–¥—É—é—Ç—å—Å—è —è–∫ —Ç–µ–Ω–∑–æ—Ä —Ä–æ–∑–º—ñ—Ä—É $S \times S \times (5B + C)$. 


.footnote[–î–∂–µ—Ä–µ–ª–æ: Redmon et al, 2015.]

---

class: middle

–î–ª—è $S=7$, $B=2$, $C=20$,  –º–µ—Ä–µ–∂–∞ –ø–µ—Ä–µ–¥–±–∞—á–∞—î –≤–µ–∫—Ç–æ—Ä —Ä–æ–∑–º—ñ—Ä—É $30$ –¥–ª—è –∫–æ–∂–Ω–æ—ó –∫–ª—ñ—Ç–∏–Ω–∫–∏. 

.center.width-100[![](figures/lec7/yolo-architecture.png)]

.footnote[–î–∂–µ—Ä–µ–ª–æ: Francois Fleuret, [EE559 Deep Learning](https://fleuret.org/ee559/), EPFL.]

---

class: middle

–ú–µ—Ä–µ–∂–∞ –≤–∏–∫–æ–Ω—É—î –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è –æ—Ü—ñ–Ω–æ–∫ –∫–ª–∞—Å—ñ–≤ —Ç–∞ —Ä–µ–≥—Ä–µ—Å—ñ–π –æ–±–º–µ–∂—É–≤–∞–ª—å–Ω–∏—Ö —Ä–∞–º–æ–∫, .bold[—ñ –Ω–µ–∑–≤–∞–∂–∞—é—á–∏ –Ω–∞ —Ç–µ, —â–æ –≤–∏—Ö—ñ–¥ —Ñ–æ—Ä–º—É—î—Ç—å—Å—è –ø–æ–≤–Ω–æ–∑–≤‚Äô—è–∑–Ω–∏–º–∏ —à–∞—Ä–∞–º–∏, –≤—ñ–Ω –∑–±–µ—Ä—ñ–≥–∞—î 2D —Å—Ç—Ä—É–∫—Ç—É—Ä—É].

- –ù–∞ –≤—ñ–¥–º—ñ–Ω—É –≤—ñ–¥ –º–µ—Ç–æ–¥—ñ–≤ –∫–æ–≤–∑–∞—é—á–æ–≥–æ –≤—ñ–∫–Ω–∞, YOLO –∞–Ω–∞–ª—ñ–∑—É—î –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è —è–∫ —î–¥–∏–Ω–µ —Ü—ñ–ª–µ.
- –ú–æ–¥–µ–ª—å –æ–±—Ä–æ–±–ª—è—î —É—Å–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è —è–∫ –Ω–∞ –µ—Ç–∞–ø—ñ –Ω–∞–≤—á–∞–Ω–Ω—è, —Ç–∞–∫ —ñ –ø—ñ–¥ —á–∞—Å —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è, —Ç–æ–º—É –Ω–µ—è–≤–Ω–æ –≤—Ä–∞—Ö–æ–≤—É—î –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–æ –∫–ª–∞—Å–∏ —Ç–∞ —ó—Ö–Ω—ñ–π –∑–æ–≤–Ω—ñ—à–Ω—ñ–π –≤–∏–≥–ª—è–¥.

.footnote[–î–∂–µ—Ä–µ–ª–æ: Francois Fleuret, [EE559 Deep Learning](https://fleuret.org/ee559/), EPFL.]

---

class: middle

–ü—ñ–¥ —á–∞—Å –Ω–∞–≤—á–∞–Ω–Ω—è YOLO –ø—Ä–∏–ø—É—Å–∫–∞—î, —â–æ –≤ –∫–æ–∂–Ω—ñ–π –∫–ª—ñ—Ç–∏–Ω—Ü—ñ —Å—ñ—Ç–∫–∏ $S \times S$ –º–æ–∂–µ –±—É—Ç–∏ —â–æ–Ω–∞–π–±—ñ–ª—å—à–µ –æ–¥–∏–Ω –æ–±‚Äô—î–∫—Ç (–∞ —Ç–æ—á–Ω—ñ—à–µ &mdash; —Ü–µ–Ω—Ç—Ä –æ–±‚Äô—î–∫—Ç–∞). –î–ª—è –∫–æ–∂–Ω–æ–≥–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –≤–∏–∑–Ω–∞—á–∞—é—Ç—å—Å—è: —ñ–Ω–¥–µ–∫—Å –∫–ª—ñ—Ç–∏–Ω–∫–∏ $i = 1, ..., S\times S$, —ñ–Ω–¥–µ–∫—Å –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–æ—ó —Ä–∞–º–∫–∏ $j = 1, ..., B$ —Ç–∞ —ñ–Ω–¥–µ–∫—Å –∫–ª–∞—Å—É $c = 1, ..., C$:

- $\mathbb{1}_i^\text{obj}$ –¥–æ—Ä—ñ–≤–Ω—é—î $1$, —è–∫—â–æ –≤ –∫–ª—ñ—Ç–∏–Ω—Ü—ñ $i$ —î –æ–±‚Äô—î–∫—Ç, —ñ $0$ ‚Äî —ñ–Ω–∞–∫—à–µ;
- $\mathbb{1}_{i,j}^\text{obj}$ –¥–æ—Ä—ñ–≤–Ω—é—î $1$, —è–∫—â–æ –≤ –∫–ª—ñ—Ç–∏–Ω—Ü—ñ $i$ —î –æ–±‚Äô—î–∫—Ç —ñ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–∞ —Ä–∞–º–∫–∞ $j$ —î —Ç—ñ—î—é, —â–æ –Ω–∞–π–∫—Ä–∞—â–µ –π–æ–≥–æ –æ–ø–∏—Å—É—î (–º–∞—î –Ω–∞–π–±—ñ–ª—å—à–µ –ø–µ—Ä–µ–∫—Ä–∏—Ç—Ç—è), —ñ $- 0$ ‚Äî —ñ–Ω–∞–∫—à–µ;
- $p_{i,c}$ –¥–æ—Ä—ñ–≤–Ω—é—î $1$, —è–∫—â–æ –≤ –∫–ª—ñ—Ç–∏–Ω—Ü—ñ $i$ —î –æ–±‚Äô—î–∫—Ç –∫–ª–∞—Å—É $c$, —ñ $0$ ‚Äî —ñ–Ω–∞–∫—à–µ;
- $x_i, y_i, w_i, h_i$ &mdash; –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∏ –∞–Ω–æ—Ç–æ–≤–∞–Ω–æ—ó –æ–±–º–µ–∂—É–≤–∞–ª—å–Ω–æ—ó —Ä–∞–º–∫–∏ –Ω–∞–≤–∫–æ–ª–æ –æ–±‚Äô—î–∫—Ç–∞ (–≤–∏–∑–Ω–∞—á–∞—é—Ç—å—Å—è —Ç—ñ–ª—å–∫–∏ —è–∫—â–æ $\mathbb{1}_i^\text{obj}=1$; –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∏ —Ç–∞ —Ä–æ–∑–º—ñ—Ä–∏ - –∑–∞–¥–∞–Ω—ñ –≤—ñ–¥–Ω–æ—Å–Ω–æ –º–µ–∂ –∫–ª—ñ—Ç–∏–Ω–∫–∏);
- $c_{i,j}$ &mdash; —Ü–µ IoU –º—ñ–∂ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–æ—é —Ä–∞–º–∫–æ—é —Ç–∞ —Ä–µ–∞–ª—å–Ω–∏–º –æ–±‚Äô—î–∫—Ç–æ–º.

.footnote[–î–∂–µ—Ä–µ–ª–æ: Francois Fleuret, [EE559 Deep Learning](https://fleuret.org/ee559/), EPFL.]

---

class: middle

–ù–∞–≤—á–∞–Ω–Ω—è –ø–æ—á–∏–Ω–∞—î—Ç—å—Å—è –∑ –æ–±—á–∏—Å–ª–µ–Ω–Ω—è $\mathbb{1}\_{i,j}^\text{obj}$ —Ç–∞ $c\_{i,j}$ –¥–ª—è –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è, –ø—ñ—Å–ª—è —á–æ–≥–æ –≤–∏–∫–æ–Ω—É—î—Ç—å—Å—è –æ–¥–∏–Ω –∫—Ä–æ–∫ –º—ñ–Ω—ñ–º—ñ–∑–∞—Ü—ñ—ó —Ñ—É–Ω–∫—Ü—ñ—ó –≤—Ç—Ä–∞—Ç:
.smaller-x[
$$
\begin{aligned}
& \lambda\_\text{coord} \sum\_{i=1}^{S \times S} \sum\_{j=1}^B \mathbb{1}\_{i,j}^\text{obj} \left( (x\_i - \hat{x}\_{i,j})^2 + (y\_i - \hat{y}\_{i,j})^2 + (\sqrt{w\_i} - \sqrt{\hat{w}\_{i,j}})^2 + (\sqrt{h\_i} - \sqrt{\hat{h}\_{i,j}})^2\right)\\\\
& + \lambda\_\text{obj} \sum\_{i=1}^{S \times S} \sum\_{j=1}^B \mathbb{1}\_{i,j}^\text{obj} (c\_{i,j} - \hat{c}\_{i,j})^2 + \lambda\_\text{noobj} \sum\_{i=1}^{S \times S} \sum\_{j=1}^B (1-\mathbb{1}\_{i,j}^\text{obj}) \hat{c}\_{i,j}^2  \\\\
& + \lambda\_\text{classes} \sum\_{i=1}^{S \times S} \mathbb{1}\_i^\text{obj} \sum\_{c=1}^C (p\_{i,c} - \hat{p}\_{i,c})^2 
\end{aligned}
$$
]

–¥–µ $\hat{p}\_{i,c}$, $\hat{x}\_{i,j}$, $\hat{y}\_{i,j}$, $\hat{w}\_{i,j}$, $\hat{h}\_{i,j}$ —Ç–∞ $\hat{c}\_{i,j}$ &mdash; —Ü–µ –∑–Ω–∞—á–µ–Ω–Ω—è, —è–∫—ñ –≥–µ–Ω–µ—Ä—É—î –Ω–µ–π—Ä–æ–º–µ—Ä–µ–∂–∞ —è–∫ —Å–≤—ñ–π –≤–∏—Ö—ñ–¥.

.footnote[–î–∂–µ—Ä–µ–ª–æ: Francois Fleuret, [EE559 Deep Learning](https://fleuret.org/ee559/), EPFL.]

---

class: middle 

–ù–∞–≤—á–∞–Ω–Ω—è YOLO –∑–∞–ª–µ–∂–∏—Ç—å –≤—ñ–¥ .bold[–±–∞–≥–∞—Ç—å–æ—Ö —ñ–Ω–∂–µ–Ω–µ—Ä–Ω–∏—Ö —Ä—ñ—à–µ–Ω—å], —â–æ –¥–æ–±—Ä–µ —ñ–ª—é—Å—Ç—Ä—É—î —Å–∫–ª–∞–¥–Ω—ñ—Å—Ç—å –ø—Ä–∞–∫—Ç–∏—á–Ω–æ–≥–æ –∑–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è –≥–ª–∏–±–æ–∫–æ–≥–æ –Ω–∞–≤—á–∞–Ω–Ω—è:
- –ø–æ–ø–µ—Ä–µ–¥–Ω—î –Ω–∞–≤—á–∞–Ω–Ω—è –ø–µ—Ä—à–∏—Ö 20 –∑–≥–æ—Ä—Ç–∫–æ–≤–∏—Ö —à–∞—Ä—ñ–≤ –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç—ñ ImageNet –¥–ª—è –∑–∞–¥–∞—á—ñ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó;
- –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –≤—Ö—ñ–¥–Ω–∏—Ö –∑–æ–±—Ä–∞–∂–µ–Ω—å —Ä–æ–∑–º—ñ—Ä–æ–º $448 \times 448$ –¥–ª—è –¥–µ—Ç–µ–∫—Ü—ñ—ó –∑–∞–º—ñ—Å—Ç—å $224 \times 224$;
- –∑–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è Leaky ReLU —è–∫ —Ñ—É–Ω–∫—Ü—ñ–π –∞–∫—Ç–∏–≤–∞—Ü—ñ—ó –¥–ª—è –≤—Å—ñ—Ö —à–∞—Ä—ñ–≤;
- –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è dropout –ø—ñ—Å–ª—è –ø–µ—Ä—à–æ–≥–æ –∑–≥–æ—Ä—Ç–∫–æ–≤–æ–≥–æ —à–∞—Ä—É;
- –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤ –æ–±–º–µ–∂—É–≤–∞–ª—å–Ω–∏—Ö —Ä–∞–º–æ–∫ –¥–æ –¥—ñ–∞–ø–∞–∑–æ–Ω—É $[0,1]$;
- –∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è –≤—Ç—Ä–∞—Ç –Ω–µ –ª–∏—à–µ –¥–ª—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –ø—Ä—è–º–æ–∫—É—Ç–Ω–∏–∫—ñ–≤, –∞–ª–µ –π –¥–ª—è –¥–æ–≤—ñ—Ä–∏ (confidence) —Ç–∞ –∫–ª–∞—Å–æ–≤–∏—Ö –æ—Ü—ñ–Ω–æ–∫;
- –∑–º–µ–Ω—à–µ–Ω–Ω—è –≤–∞–≥–∏ –≤–µ–ª–∏–∫–∏—Ö –æ–±–º–µ–∂—É–≤–∞–ª—å–Ω–∏—Ö —Ä–∞–º–æ–∫ —à–ª—è—Ö–æ–º –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –∫–≤–∞–¥—Ä–∞—Ç–Ω–æ–≥–æ –∫–æ—Ä–µ–Ω—è –∑ —ó—Ö —Ä–æ–∑–º—ñ—Ä—É —É —Ñ—É–Ω–∫—Ü—ñ—ó –≤—Ç—Ä–∞—Ç;
- –∑–º–µ–Ω—à–µ–Ω–Ω—è –≤–ø–ª–∏–≤—É –ø–æ—Ä–æ–∂–Ω—ñ—Ö –∫–æ–º—ñ—Ä–æ–∫ (—è–∫—ñ –Ω–µ –º—ñ—Å—Ç—è—Ç—å –æ–±'—î–∫—Ç—ñ–≤) —à–ª—è—Ö–æ–º –º–µ–Ω—à–æ–≥–æ –≤–∞–≥–æ–≤–æ–≥–æ –∫–æ–µ—Ñ—ñ—Ü—ñ—î–Ω—Ç–∞ —É —Ñ—É–Ω–∫—Ü—ñ—ó –≤—Ç—Ä–∞—Ç –¥–ª—è –¥–æ–≤—ñ—Ä–∏;
- –∞—É–≥–º–µ–Ω—Ç–∞—Ü—ñ—è –¥–∞–Ω–∏—Ö –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é –º–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è, —Ç—Ä–∞–Ω—Å–ª—è—Ü—ñ—ó —Ç–∞ –ø–µ—Ä–µ—Ç–≤–æ—Ä–µ–Ω—å —É –ø—Ä–æ—Å—Ç–æ—Ä—ñ HSV.

.footnote[–î–∂–µ—Ä–µ–ª–æ: Francois Fleuret, [EE559 Deep Learning](https://fleuret.org/ee559/), EPFL.]

---

class: middle, center, black-slide

<iframe width="600" height="450" src="https://www.youtube.com/embed/YmbhRxQkLMg" frameborder="0" allowfullscreen></iframe>

YOLO (Redmon, 2017).

---

exclude: true
class: middle

## SSD

The Single Shot Multi-box Detector (SSD; Liu et al, 2015) improves upon YOLO by using a fully-convolutional architecture and multi-scale maps.

.center.width-80[![](figures/lec7/ssd.png)]

.footnote[–î–∂–µ—Ä–µ–ª–æ: Francois Fleuret, [EE559 Deep Learning](https://fleuret.org/ee559/), EPFL.]

---

# Region-based CNNs (R-CNNs)

–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ –≤–µ–ª–∏–∫—ñ–π –∫—ñ–ª—å–∫–æ—Å—Ç—ñ –∑–∞–∑–¥–∞–ª–µ–≥—ñ–¥—å –≤–∏–∑–Ω–∞—á–µ–Ω–∏—Ö –±–æ–∫—Å—ñ–≤ &mdash; –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è *–ø—Ä–æ–ø–æ–∑–∏—Ü—ñ–π —Ä–µ–≥—ñ–æ–Ω—ñ–≤*, —è–∫—ñ —Å–ø–æ—á–∞—Ç–∫—É –≤–∏–¥—ñ–ª—è—é—Ç—å—Å—è –Ω–∞ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—ñ.

–ì–æ–ª–æ–≤–Ω—ñ –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∏ —Ü—å–æ–≥–æ –ø—ñ–¥—Ö–æ–¥—É &mdash; R-CNNs:
- (Slow) R-CNN (Girshick et al, 2014)
- Fast R-CNN ([Girshick et al, 2015](https://openaccess.thecvf.com/content_iccv_2015/papers/Girshick_Fast_R-CNN_ICCV_2015_paper.pdf))
- Faster R-CNN ([Ren et al, 2015](https://arxiv.org/pdf/1506.01497))
- Mask R-CNN ([He et al, 2017](https://arxiv.org/pdf/1703.06870))


.center.width-80[![](figures/lec7/new_splash-method_NaA95zW.png)]

.footnote[–î–∂–µ—Ä–µ–ª–æ: [Rich feature hierarchies for accurate object detection and semantic segmentation
Tech report (v5)](https://arxiv.org/pdf/1311.2524v5), 2014.]

???
R-CNN ‚Äî –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞ –Ω–µ–π—Ä–æ–Ω–Ω–æ—ó –º–µ—Ä–µ–∂—ñ –¥–ª—è –¥–µ—Ç–µ–∫—Ü—ñ—ó –æ–±‚Äô—î–∫—Ç—ñ–≤, —è–∫–∞ –ø–æ—î–¥–Ω—É—î:

 - –≤–∏–¥—ñ–ª–µ–Ω–Ω—è —Ä–µ–≥—ñ–æ–Ω—ñ–≤-–∫–∞–Ω–¥–∏–¥–∞—Ç—ñ–≤ (region proposals) –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é selective search;

 - –≤–∏—Ç—è–≥ –æ–∑–Ω–∞–∫ –∑ –∫–æ–∂–Ω–æ–≥–æ —Ä–µ–≥—ñ–æ–Ω—É –æ–∫—Ä–µ–º–æ –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é –≥–ª–∏–±–æ–∫–æ—ó CNN;

 - –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—é –∫–æ–∂–Ω–æ–≥–æ —Ä–µ–≥—ñ–æ–Ω—É –Ω–µ–∑–∞–ª–µ–∂–Ω–æ.

  ‚úÖ –õ–æ–∫–∞–ª—ñ–∑—É—î —Ç–∞ —Å–µ–≥–º–µ–Ω—Ç—É—î –æ–±‚Äô—î–∫—Ç–∏
  ‚ùå –ü–æ–≤—ñ–ª—å–Ω–∞: CNN –∑–∞–ø—É—Å–∫–∞—î—Ç—å—Å—è –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ —Ä–µ–≥—ñ–æ–Ω—É –æ–∫—Ä–µ–º–æ

---

class: middle

## R-CNN

–ê—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞ R-CNN —Å–∫–ª–∞–¥–∞—î—Ç—å—Å—è –∑ 4 —á–∞—Å—Ç–∏–Ω:
1. –°–µ–ª–µ–∫—Ç–∏–≤–Ω–∏–π –ø–æ—à—É–∫ –∑–∞—Å—Ç–æ—Å–æ–≤—É—î—Ç—å—Å—è –¥–æ –≤—Ö—ñ–¥–Ω–æ–≥–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó —è–∫—ñ—Å–Ω–∏—Ö —Ä–µ–≥—ñ–æ–Ω—ñ–≤-–∫–∞–Ω–¥–∏–¥–∞—Ç—ñ–≤.
2. –ü–æ–ø–µ—Ä–µ–¥–Ω—å–æ –Ω–∞–≤—á–µ–Ω–∞ –∑–≥–æ—Ä—Ç–∫–æ–≤–∞ –Ω–µ–π—Ä–æ–Ω–Ω–∞ –º–µ—Ä–µ–∂–∞ (–æ–ø–æ—Ä–Ω–∞ –º–µ—Ä–µ–∂–∞, backbone) –≤—Å—Ç–∞–≤–ª—è—î—Ç—å—Å—è –ø–µ—Ä–µ–¥ –≤–∏—Ö—ñ–¥–Ω–∏–º —à–∞—Ä–æ–º. –í–æ–Ω–∞ –º–∞—Å—à—Ç–∞–±—É—î –∫–æ–∂–µ–Ω –∑–∞–ø—Ä–æ–ø–æ–Ω–æ–≤–∞–Ω–∏–π —Ä–µ–≥—ñ–æ–Ω –¥–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ–≥–æ —Ä–æ–∑–º—ñ—Ä—É —Ç–∞ –≤–∏–∫–æ–Ω—É—î –ø—Ä—è–º–∏–π –ø—Ä–æ—Ö—ñ–¥, —â–æ–± –æ—Ç—Ä–∏–º–∞—Ç–∏ –≤–µ–∫—Ç–æ—Ä –æ–∑–Ω–∞–∫ –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ —Ä–µ–≥—ñ–æ–Ω—É.
3. –û—Ç—Ä–∏–º–∞–Ω—ñ –æ–∑–Ω–∞–∫–∏ –ø–æ–¥–∞—é—Ç—å—Å—è –Ω–∞ SVM-–∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ç–æ—Ä –¥–ª—è –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è –∫–ª–∞—Å—É –æ–±‚Äô—î–∫—Ç–∞.
4. –¢—ñ –∂ –æ–∑–Ω–∞–∫–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—Ç—å—Å—è –≤ –ª—ñ–Ω—ñ–π–Ω—ñ–π —Ä–µ–≥—Ä–µ—Å—ñ—ó –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –æ–±–º–µ–∂—É–≤–∞–ª—å–Ω–æ—ó —Ä–∞–º–∫–∏ (bounding box).

.center.width-90[![](figures/lec7/r-cnn.svg)]

.footnote[–î–∂–µ—Ä–µ–ª–æ: [Dive Into Deep Learning](https://d2l.ai/), 2020.]

???
–ü—ñ–¥ "—è–∫—ñ—Å–Ω–∏–º–∏" –º–∞—é—Ç—å—Å—è –Ω–∞ —É–≤–∞–∑—ñ —Ä–µ–≥—ñ–æ–Ω–∏ –∑ –≤–∏—Å–æ–∫–∏–º –ø–µ—Ä–µ–∫—Ä–∏—Ç—Ç—è–º (IoU) –∑ —Ä–µ–∞–ª—å–Ω–∏–º–∏ –æ–±‚Äô—î–∫—Ç–∞–º–∏.

---

class: middle

.center.width-90[![](figures/lec7/selective-search.png)]

–°–µ–ª–µ–∫—Ç–∏–≤–Ω–∏–π –ø–æ—à—É–∫ (Uijlings et al, 2013) –≥—Ä—É–ø—É—î —Å—É—Å—ñ–¥–Ω—ñ –ø—ñ–∫—Å–µ–ª—ñ –∑—ñ —Å—Ö–æ–∂–æ—é —Ç–µ–∫—Å—Ç—É—Ä–æ—é, –∫–æ–ª—å–æ—Ä–æ–º –∞–±–æ —è—Å–∫—Ä–∞–≤—ñ—Å—Ç—é,
–∞–Ω–∞–ª—ñ–∑—É—é—á–∏ –≤—ñ–∫–Ω–∞ —Ä—ñ–∑–Ω–∏—Ö —Ä–æ–∑–º—ñ—Ä—ñ–≤ –Ω–∞ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—ñ.

---

class: middle

.grid[
.kol-3-5[
<br><br>

## Fast R-CNN

- R-CNN –ø–æ–≤—ñ–ª—å–Ω–∞, –æ—Å–∫—ñ–ª—å–∫–∏ –æ–∑–Ω–∞–∫–∏ –≤–∏—Ç—è–≥—É—é—Ç—å—Å—è –æ–∫—Ä–µ–º–æ –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ —Ä–µ–≥—ñ–æ–Ω—É-–∫–∞–Ω–¥–∏–¥–∞—Ç–∞.
- Fast R-CNN –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î –≤—Å–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è —è–∫ –≤—Ö—ñ–¥ –¥–ª—è CNN —ñ –≤–∏—Ç—è–≥—É—î —Å–ø—ñ–ª—å–Ω—É –∫–∞—Ä—Ç—É –æ–∑–Ω–∞–∫, –∑–∞–º—ñ—Å—Ç—å –æ–±—Ä–æ–±–∫–∏ –∫–æ–∂–Ω–æ–≥–æ —Ä–µ–≥—ñ–æ–Ω—É –æ–∫—Ä–µ–º–æ.
- Fast R-CNN –≤–≤–æ–¥–∏—Ç—å RoI pooling, —è–∫–∏–π –¥–æ–∑–≤–æ–ª—è—î –æ—Ç—Ä–∏–º—É–≤–∞—Ç–∏ –≤–µ–∫—Ç–æ—Ä–∏ –æ–∑–Ω–∞–∫ —Ñ—ñ–∫—Å–æ–≤–∞–Ω–æ–≥–æ —Ä–æ–∑–º—ñ—Ä—É –¥–ª—è —Ä–µ–≥—ñ–æ–Ω—ñ–≤-–∫–∞–Ω–¥–∏–¥–∞—Ç—ñ–≤ —Ä—ñ–∑–Ω–æ–≥–æ —Ä–æ–∑–º—ñ—Ä—É.

]
.kol-2-5[.width-100[![](figures/lec7/fast-rcnn.svg)]

.width-100[![](figures/lec7/fast-rcnn.png)]]
]

.footnote[–î–∂–µ—Ä–µ–ª–æ: [Dive Into Deep Learning](https://d2l.ai/), 2020.]

---

class: middle

.center.width-70[![](figures/lec7/faster-rcnn.svg)]

## Faster R-CNN

- –ü—Ä–æ–¥—É–∫—Ç–∏–≤–Ω—ñ—Å—Ç—å —è–∫ R-CNN, —Ç–∞–∫ —ñ Fast R-CNN –∑–∞–ª–µ–∂–∏—Ç—å –≤—ñ–¥ —è–∫–æ—Å—Ç—ñ —Ä–µ–≥—ñ–æ–Ω—ñ–≤-–∫–∞–Ω–¥–∏–¥–∞—Ç—ñ–≤, –æ—Ç—Ä–∏–º–∞–Ω–∏—Ö –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é —Å–µ–ª–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –ø–æ—à—É–∫—É.
- Faster R-CNN –∑–∞–º—ñ–Ω—é—î —Å–µ–ª–µ–∫—Ç–∏–≤–Ω–∏–π –ø–æ—à—É–∫ –Ω–∞ –º–µ—Ä–µ–∂—É –ø—Ä–æ–ø–æ–∑–∏—Ü—ñ–π —Ä–µ–≥—ñ–æ–Ω—ñ–≤ (Region Proposal Network, RPN).
- –¶—è –º–µ—Ä–µ–∂–∞ –∑–º–µ–Ω—à—É—î –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∑–∞–ø—Ä–æ–ø–æ–Ω–æ–≤–∞–Ω–∏—Ö —Ä–µ–≥—ñ–æ–Ω—ñ–≤, –∑–±–µ—Ä—ñ–≥–∞—é—á–∏ –≤–∏—Å–æ–∫—É —Ç–æ—á–Ω—ñ—Å—Ç—å –≤–∏—è–≤–ª–µ–Ω–Ω—è –æ–±‚Äô—î–∫—Ç—ñ–≤.—ñ

.footnote[–î–∂–µ—Ä–µ–ª–æ: [Dive Into Deep Learning](https://d2l.ai/), 2020.]

---

class: middle, center, black-slide

<iframe width="600" height="450" src="https://www.youtube.com/embed/V4P_ptn2FF4" frameborder="0" allowfullscreen></iframe>

YOLO (v2) vs YOLO 9000 vs SSD vs Faster RCNN

---

class: middle

# –û—Å–Ω–æ–≤–Ω—ñ –≤–∏—Å–Ω–æ–≤–∫–∏

- –û–¥–Ω–æ–µ—Ç–∞–ø–Ω—ñ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∏ (YOLO, SSD, RetinaNet —Ç–æ—â–æ) &mdash; —à–≤–∏–¥–∫—ñ –¥–ª—è —ñ–Ω—Ñ–µ—Ä–µ–Ω—Å—É, –∞–ª–µ –∑–∞–∑–≤–∏—á–∞–π –Ω–µ –Ω–∞–π—Ç–æ—á–Ω—ñ—à—ñ –¥–ª—è –≤–∏—è–≤–ª–µ–Ω–Ω—è –æ–±'—î–∫—Ç—ñ–≤.
- –î–≤–æ–µ—Ç–∞–ø–Ω—ñ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∏ (Fast R-CNN, Faster R-CNN, R-FCN, Light head R-CNN, —Ç–æ—â–æ) &mdash; –∑–∞–∑–≤–∏—á–∞–π –ø–æ–≤—ñ–ª—å–Ω—ñ—à—ñ, –∞–ª–µ —á–∞—Å—Ç–æ —î —Ç–æ—á–Ω—ñ—à–∏–º–∏.
- –í–∏–±—ñ—Ä –º–µ—Ä–µ–∂—ñ –∑–∞–ª–µ–∂–∞—Ç—å –≤—ñ–¥ –±–∞–≥–∞—Ç—å–æ—Ö —ñ–Ω–∂–µ–Ω–µ—Ä–Ω–∏—Ö —Ä—ñ—à–µ–Ω—å.

---

class: middle, center

.larger-xxx[üßø[–î–µ–º–æ](https://colab.research.google.com/gist/kirisakow/325a557d89262e8d6a4f2918917e82b4/real-time-object-detection-in-webcam-video-stream-using-ultralytics-yolov8.ipynb)]

???

Use Lucie's kitchen set.
- Far vs. near detections
- Individual vs. packed detections
- Rotation, flip, etc

---

class: blue-slide, middle, center
count: false

.larger-xx[–°–µ–≥–º–µ–Ω—Ç–∞—Ü—ñ—è]

---

class: middle

.center.width-90[![](figures/lec7/segmentation.png)]

Segmentation is the task of partitioning an image, at the pixel level, into regions:
- .bold[Semantic segmentation]: All pixels in an image are labeled with their class (e.g., car, pedestrian, road).
- .bold[Instance segmentation]: Pixels of detected objects are labeled with an instance ID (e.g., car 1, car 2, pedestrian 1).
- Panoptic segmentation: Combines semantic and instance segmentation. All pixels in an image are labeled with a class and an instance ID (if applicable).

.footnote[–î–∂–µ—Ä–µ–ª–æ: [Dive Into Deep Learning](https://d2l.ai/), 2020.]

---

class: middle

The deep learning approach casts semantic segmentation as pixel classification. Convolutional networks can be used for that purpose, but with a few adaptations.

---

class: middle

.center.width-100[![](figures/lec7/fcn-1.png)]

.footnote[–î–∂–µ—Ä–µ–ª–æ: [CS231n, Lecture 11](http://cs231n.stanford.edu/slides/2018/cs231n_2018_lecture11.pdf), 2018.]

---

class: middle

.center.width-100[![](figures/lec7/fcn-2.png)]

.footnote[–î–∂–µ—Ä–µ–ª–æ: [CS231n, Lecture 11](http://cs231n.stanford.edu/slides/2018/cs231n_2018_lecture11.pdf), 2018.]

???

Convolution and pooling layers reduce the input width and height, or keep them unchanged.

Semantic segmentation requires to predict values for each pixel, and therefore needs to increase input width and height.

Fully connected layers could be used for that purpose but would face the same limitations as before (spatial specialization, too many parameters).

Ideally, we would like layers that implement the inverse of convolutional
 and pooling layers.

---

class: middle

## Transposed convolution

A **transposed convolution** is a convolution where the implementation of the forward and backward passes
are swapped.

Given a convolutional kernel $\mathbf{u}$,
- the forward pass is implemented as $v(\mathbf{h}) = \mathbf{U}^T v(\mathbf{x})$ with appropriate reshaping, thereby effectively up-sampling an input $v(\mathbf{x})$ into a larger one;
- the backward pass is computed by multiplying the loss by $\mathbf{U}$ instead of $\mathbf{U}^T$.

???

In a regular convolution,
- the forward pass is equivalent to $v(\mathbf{h}) = \mathbf{U} v(\mathbf{x})$;
- the backward pass is computed by multiplying the loss by $\mathbf{U}^T$.

Transposed convolutions are also referred to as fractionally-strided convolutions or deconvolutions (mistakenly).

---

class: middle

.pull-right[<br><br>![](figures/lec7/no_padding_no_strides_transposed.gif)]

$$
\begin{aligned}
\mathbf{U}^T v(\mathbf{x}) &= v(\mathbf{h}) \\\\
\begin{pmatrix}
1 & 0 & 0 & 0 \\\\
4 & 1 & 0 & 0 \\\\
1 & 4 & 0 & 0 \\\\
0 & 1 & 0 & 0 \\\\
1 & 0 & 1 & 0 \\\\
4 & 1 & 4 & 1 \\\\
3 & 4 & 1 & 4 \\\\
0 & 3 & 0 & 1 \\\\
3 & 0 & 1 & 0 \\\\
3 & 3 & 4 & 1 \\\\
1 & 3 & 3 & 4 \\\\
0 & 1 & 0 & 3 \\\\
0 & 0 & 3 & 0 \\\\
0 & 0 & 3 & 3 \\\\
0 & 0 & 1 & 3 \\\\
0 & 0 & 0 & 1
\end{pmatrix}
\begin{pmatrix}
2 \\\\
1 \\\\
4 \\\\
4
\end{pmatrix} &=
\begin{pmatrix}
2 \\\\
9 \\\\
6 \\\\
1 \\\\
6 \\\\
29 \\\\
30 \\\\
7 \\\\
10 \\\\
29 \\\\
33 \\\\
13 \\\\
12 \\\\
24 \\\\
16 \\\\
4
\end{pmatrix}
\end{aligned}$$

.footnote[–î–∂–µ—Ä–µ–ª–æ: Dumoulin and Visin, [A guide to convolution arithmetic for deep learning](https://arxiv.org/abs/1603.07285), 2016.]

---

class: middle

## Fully convolutional networks (FCNs)

.grid[
.kol-3-4[

A fully convolutional network (FCN) is a convolutional network that replaces the fully connected layers with convolutional layers and transposed convolutional layers. 

For semantic segmentation, the simplest design of a fully convolutional network consists in:
- using a (pre-trained) convolutional network for downsampling and extracting image features;
- replacing the dense layers with a  $1 \times 1$ convolution layer to  transform the number of channels into the number of categories;
- upsampling the feature map to the size of the input image by using one (or several) transposed convolution layer(s).
]
.kol-1-4[.center.width-90[![](figures/lec7/fcn.svg)]]
]

---

class: middle

Contrary to fully connected networks, the dimensions of the output of a fully convolutional network is not fixed. It directly depends on the dimensions of the input, which can be images of arbitrary sizes.

---

exclude: true
class: middle

.center.width-100[![](figures/lec7/fcn-convdeconv.png)]

.footnote[–î–∂–µ—Ä–µ–ª–æ: [Noh et al](https://arxiv.org/abs/1505.04366), 2015.]

---

class: middle

.center.width-100[![](figures/lec7/ConvSemSeg.svg)]

The previous .bold[encoder-decoder architecture] is a simple and effective way to perform semantic segmentation. 

However, the low-resolution representation in the middle of the network can be a bottleneck for the segmentation performance, as it must retain enough information to reconstruct the high-resolution segmentation map.

.footnote[–î–∂–µ—Ä–µ–ª–æ: Simon J.D. Prince, [Understanding Deep Learning](https://udlbook.github.io/udlbook/), 2023.]

---

class: middle

## UNet

The .bold[UNet] architecture is an encoder-decoder architecture with skip connections (usually concatenations) that directly connect the encoder and decoder layers at the same resolution. In this way, the decoder can use both
- the corresponding high-resolution features from the encoder, and
- the lower-resolution features from the previous layers.

.center.width-80[![](figures/lec7/ResidualUNet.svg)]

.footnote[–î–∂–µ—Ä–µ–ª–æ: Simon J.D. Prince, [Understanding Deep Learning](https://udlbook.github.io/udlbook/), 2023.]

???

Take the time to explain that that same architecture can be used for image to image mappings, as in some of their projects.

Insist once again on the increasing number of kernels (=out_channels) in the encoder and the decreasing number of kernels in the decoder.

Mention the final 1x1 convolution to reduce the number of channels to the number of classes.

---

class: middle

.center.width-100[![](figures/lec7/ResidualUNetResults.svg)]

.center[3d segmentation results using a UNet architecture.<br> (a) Slices of a 3d volume of a mouse cortex, (b) A UNet is used to classify voxels as either inside or outside neutrites. Connected regions are shown with different colors, (c) 5-member ensemble of UNets.]


.footnote[–î–∂–µ—Ä–µ–ª–æ: Simon J.D. Prince, [Understanding Deep Learning](https://udlbook.github.io/udlbook/), 2023.]

---

class: middle

.center[(demo)]

---

class: middle

## Mask R-CNN

.grid[
.kol-1-2[

Segmentation is a natural extension of object detection. For example, Mask R-CNN extends the Faster R-CNN model for semantic segmentation: 
- The RoI pooling layer is replaced with an RoI alignment layer. 
- It branches off to an FCN for predicting a semantic segmentation mask.
- Object detection combined with mask prediction enables *instance segmentation*.


]
.kol-1-2[.center.width-95[![](figures/lec7/mask-rcnn.svg)]]
]

.footnote[–î–∂–µ—Ä–µ–ª–æ: [Dive Into Deep Learning](https://d2l.ai/), 2020.]

---

class: middle

.center.width-100[![](figures/lec7/mask-rcnn-results.png)]

.footnote[–î–∂–µ—Ä–µ–ª–æ: [He et al](https://arxiv.org/abs/1703.06870), 2017.]

---

class: middle, center, black-slide

<iframe width="600" height="450" src="https://www.youtube.com/embed/OOT3UIXZztE" frameborder="0" allowfullscreen></iframe>

---

class: middle

It is noteworthy that for detection and segmentation, there is an heavy
re-use of large networks trained for classification.

.bold[The models themselves, as much as the source code of the algorithm that
produced them, or the training data, are generic and re-usable assets.]

.footnote[–î–∂–µ—Ä–µ–ª–æ: Francois Fleuret, [EE559 Deep Learning](https://fleuret.org/ee559/), EPFL.]

---

class: end-slide, center
count: false

.larger-xxxx[üèÅ]

???

Quiz:
- What architecture would you use on images?
- Would you train from scratch?
- What is the difference between object detection and segmentation?
- Name one architecture for object detection.
- Name one architecture for semantic segmentation.
- What kind of layer can you use to upscale a feature map?